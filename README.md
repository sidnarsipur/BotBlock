# BotBlock

Generate custom [robots.txt](https://developers.google.com/search/docs/crawling-indexing/robots/intro) files from your sitemap.xml. 

BotBlock takes in your sitemap and allows you to generate a tailored robots.txt file that only blocks certain pages, file types, and crawlers.

<br>

<img width="1457" height="867" alt="Screenshot 2025-11-19 at 4 25 11â€¯AM" src="https://github.com/user-attachments/assets/085c5ced-2997-4211-a6e4-60df77d69432" />
