# Protect.AI
Protect your website and/or web content from unauthorized model training by adding a [robots.txt](https://www.cloudflare.com/learning/bots/what-is-robots-txt/) file. 

Protect.AI reads your website's [sitemap](https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview) and generates a robots.txt depending on which pages, file and/or file types you want to protect. Select the SEO ALLOWED option to allow only SEO bots to crawl your site and prevent traffic disruption. 

## Run Backend
`cd backend`
`make run`
