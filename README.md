# BotBlock

Generate custom [robots.txt](https://developers.google.com/search/docs/crawling-indexing/robots/intro) files from your sitemap.xml. 

BotBlock takes in your sitemap and allows you to generate a tailored robots.txt file that only blocks certain pages, file types, and crawlers.

<br>

<img width="1137" height="753" alt="Screenshot 2025-11-19 at 2 03 18â€¯AM" src="https://github.com/user-attachments/assets/26f0f9f2-8bc6-4343-b02a-e8434d320fa5" />
