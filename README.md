# BotBlock

Generate custom [robots.txt](https://developers.google.com/search/docs/crawling-indexing/robots/intro) files from your sitemap.xml. 

BotBlock takes in your sitemap and allows you to generate a tailored robots.txt file that only blocks certain pages, file types, and crawlers.

<br>

<p float="left">
  <img src="https://github.com/user-attachments/assets/085c5ced-2997-4211-a6e4-60df77d69432" width="49%" />
  <img src="https://github.com/user-attachments/assets/63ddd4a5-e5dc-4d94-b962-9330a9c42524" width="49%" />
</p>

<p>
  <img src="https://github.com/user-attachments/assets/bb4da3b2-a16e-41ec-8215-38a2ac498a8c" width="45%" />
</p>

